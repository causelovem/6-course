{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение пневмонии на рентгеновских снимках\n",
    "\n",
    "Это задание посвящено детектированию пневмонии на рентгеновских снимках груди.\n",
    "\n",
    "Ваша цель — создать точный алгоритм детектирования визуальных свидетельств пневмонии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import KFold\n",
    "import pydicom\n",
    "from tqdm import tqdm_notebook\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.rpn import RPNHead\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget для скачивания torchvision utils, которые не входят в pypi\n",
    "!wget https://raw.githubusercontent.com/pytorch/vision/master/references/detection/utils.py -O utils.py\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dicom_fps(data_dir):\n",
    "    dicom_fps = glob.glob(os.path.join(data_dir, \"*.dcm\"))\n",
    "    return list(set(dicom_fps))\n",
    "\n",
    "\n",
    "def parse_dataset(data_dir, anns):\n",
    "    image_fps = get_dicom_fps(data_dir)\n",
    "    image_annotations = {fp: [] for fp in image_fps}\n",
    "    for index, row in anns.iterrows():\n",
    "        fp = os.path.join(data_dir, row[\"patientId\"] + \".dcm\")\n",
    "        image_annotations.get(fp, []).append(row)\n",
    "    return image_fps, image_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузим датасет\n",
    "\n",
    "Данные скачивались с https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data . Для дальнейшей работы укажите в переменной data_path локальный путь к данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = \"data/rsna-pneumonia-detection-challenge/\"\n",
    "train_img_path = os.path.join(data_path, \"stage_2_train_images\")\n",
    "annotations = pd.read_csv(os.path.join(data_path, \"stage_2_train_labels.csv\"))\n",
    "\n",
    "image_fps, image_annotations = parse_dataset(train_img_path, anns=annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим на мета-информацию в .dcm файлах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pydicom.read_file(image_fps[0])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой табличке для каждого пациента содержится информация о расположении поражений легких. Часть пациентов здорова, на таких изображениях стоит метка 0 и нет контура объекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Класс для работы с изображениями в pytorch\n",
    "\n",
    "Основная функция __\\_\\_getitem\\_\\___ — возвращает тензор изображения и метки к нему. Поля в словаре target подчиняются требованием torchvision (репозиторий с предобученными моделями, https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class RSNADataset(Dataset):\n",
    "    def __init__(self, image_fps, image_annotations, orig_height, orig_width, train=True):\n",
    "        self.image_fps = image_fps\n",
    "        self.image_annotations = image_annotations\n",
    "        self.orig_height = orig_height\n",
    "        self.orig_width = orig_width\n",
    "\n",
    "        image_info = dict()\n",
    "        for image_idx, file_path in enumerate(image_fps):\n",
    "            annotations = image_annotations[file_path]\n",
    "            image_info[image_idx] = {\"path\": file_path,\n",
    "                                     \"annotations\": annotations}\n",
    "        self.image_info = image_info\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_fps)\n",
    "\n",
    "    def show_image(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        fp = info[\"path\"]\n",
    "        ds = pydicom.read_file(fp)\n",
    "        image = ds.pixel_array\n",
    "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "            image = np.stack((image,) * 3, -1)\n",
    "        return image\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        fp = info[\"path\"]\n",
    "        ds = pydicom.read_file(fp)\n",
    "        image = ds.pixel_array\n",
    "        image = np.array(Image.fromarray(image).resize((self.orig_width, self.orig_height)))\n",
    "\n",
    "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "            image = np.stack((image,) * 3, -1)\n",
    "\n",
    "        image = np.rollaxis(image, 2, 0) / 255\n",
    "        return image\n",
    "\n",
    "    def load_bbox(self, image_id, scale_factor):\n",
    "        info = self.image_info[image_id]\n",
    "        annotations = info[\"annotations\"]\n",
    "        count = len(annotations)\n",
    "        if count == 0 or all((ann[\"Target\"] == 0 for ann in annotations)):\n",
    "            # Пневмонии нет, считаем за объект все фото\n",
    "            xmin = 0\n",
    "            xmax = 1024 * scale_factor\n",
    "            ymin = 0\n",
    "            ymax = 1024 * scale_factor\n",
    "            boxes = torch.as_tensor([[xmin, ymin, xmax, ymax]], dtype=torch.float32)\n",
    "            class_ids = np.zeros((1,), dtype=np.int32)\n",
    "        else:\n",
    "            boxes = []\n",
    "            mask = np.zeros((self.orig_height, self.orig_width, count), dtype=np.uint8)\n",
    "            class_ids = np.zeros((count,), dtype=np.int32)\n",
    "            for annotation_num, annotation in enumerate(annotations):\n",
    "                if annotation[\"Target\"] == 1:\n",
    "                    x = int(annotation[\"x\"])\n",
    "                    y = int(annotation[\"y\"])\n",
    "                    w = int(annotation[\"width\"])\n",
    "                    h = int(annotation[\"height\"])\n",
    "                    xmin = int(max(x * scale_factor, 0))\n",
    "                    xmax = int(min((x + w) * scale_factor, self.orig_width))\n",
    "                    ymin = int(max(y * scale_factor, 0))\n",
    "                    ymax = int(min((y + h) * scale_factor, self.orig_height))\n",
    "                    box = [xmin, ymin, xmax, ymax]\n",
    "\n",
    "                    boxes.append(box)\n",
    "                    class_ids[annotation_num] = 1\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        return boxes, class_ids.astype(np.int32)\n",
    "\n",
    "    \n",
    "    def mask_to_bbox(self, masks, scale_factor):\n",
    "        boxes = []\n",
    "        for bbox in masks:\n",
    "            pos = np.where(bbox[:, :])\n",
    "            xmin = int(max(np.min(pos[1]) * scale_factor, 0))\n",
    "            xmax = int(min(np.max(pos[1]) * scale_factor, self.orig_width))\n",
    "            ymin = int(max(np.min(pos[0]) * scale_factor, 0))\n",
    "            ymax = int(min(np.max(pos[0]) * scale_factor, self.orig_height))\n",
    "            box = [xmin, ymin, xmax, ymax]\n",
    "            boxes.append(box)\n",
    "            if xmin >= xmax:\n",
    "                print(xmin, xmax)\n",
    "            if ymin >= ymax:\n",
    "                print(ymin, ymax)\n",
    "            assert xmin < xmax\n",
    "            assert ymin < ymax\n",
    "\n",
    "        torch_boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        return torch_boxes\n",
    "\n",
    "    @staticmethod\n",
    "    def get_area(boxes):\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        return area\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        scale_factor = self.orig_width / 1024\n",
    "\n",
    "        boxes, labels = self.load_bbox(index, scale_factor)\n",
    "        img = torch.Tensor(self.load_image(index))\n",
    "\n",
    "        if np.all(labels == 0):\n",
    "            area = self.get_area(boxes)\n",
    "            iscrowd = torch.ones((len(boxes),), dtype=torch.int64)\n",
    "            labels = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "        else:\n",
    "            area = self.get_area(boxes)\n",
    "            labels = torch.ones((boxes.shape[0],), dtype=torch.int64)\n",
    "            iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
    "\n",
    "        target = {\"image_id\": torch.tensor([index]),\n",
    "              \"boxes\": boxes,\n",
    "              \"labels\": labels,\n",
    "              \"area\": area,\n",
    "              \"iscrowd\": iscrowd\n",
    "             }\n",
    "\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим на случайное изображение больного пациента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_random_image(dataset):\n",
    "    class_ids = [0]\n",
    "    while class_ids[0] == 0:\n",
    "        image_id = random.choice(range(len(dataset.image_fps)))\n",
    "        image_fp = dataset.image_fps[image_id]\n",
    "        image = dataset.show_image(image_id)\n",
    "        boxes, class_ids = dataset.load_bbox(image_id, scale_factor=1)\n",
    "        if len(boxes) == 0:\n",
    "            continue\n",
    "        mask_instance = np.zeros((dataset.orig_height, dataset.orig_width), dtype=np.uint8)\n",
    "        xmin, ymin, xmax, ymax = boxes[0][0], boxes[0][1], boxes[0][2], boxes[0][3]\n",
    "        mask = cv2.rectangle(mask_instance, (xmin, ymin), (xmax, ymax), 255, -1)\n",
    "        mask = np.array(mask)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    masked = np.zeros(image.shape[:2])\n",
    "    masked = image[:, :, 0] * mask\n",
    "    \n",
    "    plt.imshow(masked, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "img_size = 1024\n",
    "dataset = RSNADataset(image_fps[:2000], image_annotations, img_size, img_size, train=True)\n",
    "visualize_random_image(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция для получения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    # Предобученная на COCO fasterrcnn\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    \n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # Заменим \"голову\" классификатора на новую, которую обучим на нашем датасете\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256),),\n",
    "                                       aspect_ratios=((0.25, 0.5, 1.0, 1.5, 2.0),))\n",
    "    roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0],\n",
    "                                                    output_size=32,\n",
    "                                                    sampling_ratio=2)\n",
    "    model.box_roi_pool = roi_pooler\n",
    "    model.rpn_anchor_generator = anchor_generator\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательные функции для обучения и оценки качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# источник: https://www.kaggle.com/chenyc15/mean-average-precision-metric\n",
    "def iou(box1, box2):\n",
    "    x11, y11, x12, y12 = box1\n",
    "    x21, y21, x22, y22 = box2\n",
    "    \n",
    "    w1 = x12 - x11\n",
    "    h1 = y12 - y11\n",
    "    w2 = x22 - x21\n",
    "    h2 = y22 - y21\n",
    "    \n",
    "    area1, area2 = w1 * h1, w2 * h2\n",
    "    xi1, yi1, xi2, yi2 = max([x11, x21]), max([y11, y21]), min([x12, x22]), min([y12, y22])\n",
    "    \n",
    "    if xi2 <= xi1 or yi2 <= yi1:\n",
    "        return 0\n",
    "    else:\n",
    "        intersect = (xi2 - xi1) * (yi2 - yi1)\n",
    "        union = area1 + area2 - intersect\n",
    "        return intersect / union\n",
    "\n",
    "\n",
    "def map_iou(boxes_true, boxes_pred, scores, thresholds = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75]):\n",
    "    \"\"\"\n",
    "    Mean average precision at differnet intersection over union (IoU) threshold\n",
    "    \n",
    "    input:\n",
    "        boxes_true: Mx4 numpy array of ground true bounding boxes of one image. \n",
    "                    bbox format: (x1, y1, x2, y2)\n",
    "        boxes_pred: Nx4 numpy array of predicted bounding boxes of one image. \n",
    "                    bbox format: (x1, y1, x2, y2)\n",
    "        scores:     length N numpy array of scores associated with predicted bboxes\n",
    "        thresholds: IoU shresholds to evaluate mean average precision on\n",
    "    output: \n",
    "        map: mean average precision of the image\n",
    "    \"\"\"\n",
    "    \n",
    "    # According to the introduction, images with no ground truth bboxes will not be \n",
    "    # included in the map score unless there is a false positive detection (?)\n",
    "        \n",
    "    # return None if both are empty, don't count the image in final evaluation (?)\n",
    "    if len(boxes_true) == 0 and len(boxes_pred) == 0:\n",
    "        return None\n",
    "    \n",
    "    assert boxes_true.shape[1] == 4 or boxes_pred.shape[1] == 4, \"boxes should be 2D arrays with shape[1]=4\"\n",
    "    if len(boxes_pred):\n",
    "        assert len(scores) == len(boxes_pred), \"boxes_pred and scores should be same length\"\n",
    "        # sort boxes_pred by scores in decreasing order\n",
    "        boxes_pred = boxes_pred[np.argsort(scores)[::-1], :]\n",
    "    \n",
    "    map_total = 0\n",
    "    \n",
    "    # loop over thresholds\n",
    "    for t in thresholds:\n",
    "        matched_bt = set()\n",
    "        tp, fn = 0, 0\n",
    "        for i, bt in enumerate(boxes_true):\n",
    "            matched = False\n",
    "            for j, bp in enumerate(boxes_pred):\n",
    "                miou = iou(bt, bp)\n",
    "                if miou >= t and not matched and j not in matched_bt:\n",
    "                    matched = True\n",
    "                    tp += 1 # bt is matched for the first time, count as TP\n",
    "                    matched_bt.add(j)\n",
    "            if not matched:\n",
    "                fn += 1 # bt has no match, count as FN\n",
    "                \n",
    "        fp = len(boxes_pred) - len(matched_bt) # FP is the bp that not matched to any bt\n",
    "        m = tp / (tp + fn + fp)\n",
    "        map_total += m\n",
    "    \n",
    "    return map_total / len(thresholds)\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    boxes_pred = []\n",
    "    boxes_true = []\n",
    "    scores = []\n",
    "    summ = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for images, targets in tqdm_notebook(data_loader):\n",
    "            boxes_true_mini_batch = [np.array(item[\"boxes\"]) for item in targets]\n",
    "            labels_true_mini_batch = [np.array(item[\"labels\"]) for item in targets]\n",
    "            images = list(img.to(device) for img in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            outputs = model(images)\n",
    "            outputs = [{k: v.to(device) for k, v in t.items()} for t in outputs]\n",
    "\n",
    "            res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
    "            boxes_pred_mini_batch = [np.array(res[\"boxes\"].to(\"cpu\")) for res in outputs]\n",
    "            scores_mini_batch = [np.array(res[\"scores\"].to(\"cpu\")) for res in outputs]\n",
    "            labels_mini_batch = [np.array(res[\"labels\"].to(\"cpu\")) for res in outputs]\n",
    "\n",
    "            for img_num in range(len(images)):\n",
    "                # Если на картинке нет пневмонии\n",
    "                if np.all(labels_true_mini_batch[img_num] == 0):\n",
    "                    if (labels_mini_batch[img_num].size == 0) or np.all(labels_mini_batch[img_num] == 0):\n",
    "                        continue\n",
    "                    else:\n",
    "                        # Мы сказали, что есть\n",
    "                        count += 1\n",
    "                else:\n",
    "                    # Если пневмония есть считаем map_iou\n",
    "                    curr_map_iou = map_iou(boxes_true_mini_batch[img_num], \n",
    "                                           boxes_pred_mini_batch[img_num], \n",
    "                                           scores_mini_batch[img_num])\n",
    "                    summ += curr_map_iou\n",
    "                    count += 1\n",
    "                \n",
    "    return summ / count\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n",
    "    model.train()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "\n",
    "    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # reduce losses over all GPUs for logging purposes\n",
    "        loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
    "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "        loss_value = losses_reduced.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "            print(loss_dict_reduced)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
    "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение и валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_validation(images_files, cv, params):\n",
    "    img_size = params.get(\"img_size\", 1024)\n",
    "    num_classes = params.get(\"num_classes\", 2)\n",
    "    num_epochs = params.get(\"num_epochs\", 5)\n",
    "    device = params.get(\"device\", \"cpu\")\n",
    "    \n",
    "    scores = np.zeros(len(cv))\n",
    "    for fold_num, (train_idx, val_idx) in enumerate(cv):\n",
    "        train_images = list(images_files[train_idx])\n",
    "        # Будем обучаться только на изображениях с пневмонией\n",
    "        train_images = [filename for filename in train_images if image_annotations[filename][0].Target > 0]\n",
    "        val_images = list(images_files[val_idx])\n",
    "\n",
    "        dataset = RSNADataset(train_images, image_annotations, img_size, img_size, train=True)\n",
    "\n",
    "        dataset_val = RSNADataset(val_images, image_annotations, img_size, img_size, train=False)\n",
    "\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=6, shuffle=True, num_workers=6, collate_fn=collate_fn)\n",
    "\n",
    "        data_loader_val = torch.utils.data.DataLoader(\n",
    "            dataset_val, batch_size=6, shuffle=False, num_workers=6,\n",
    "            collate_fn=collate_fn)\n",
    "\n",
    "        model = get_model(num_classes)\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        params = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                                    momentum=0.9, weight_decay=0.00005)\n",
    "\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                       step_size=2,\n",
    "                                                       gamma=0.1)\n",
    "\n",
    "\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"epoch {}\".format(epoch))\n",
    "            train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            fold_score = evaluate(model, data_loader_val, device=device)\n",
    "            print(\"score: {}\".format(fold_score))\n",
    "            scores[fold_num] = fold_score\n",
    "        \n",
    "        torch.save(model.state_dict(), \"fold_num_{}_model\".format(fold_num))\n",
    "        del model\n",
    "        \n",
    "    print(\"average val score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Для аккуратной валидации используйте больше разбиений\n",
    "n_splits = 1\n",
    "cv = list(ShuffleSplit(n_splits=n_splits, random_state=15, test_size=0.2).split(np.zeros((len(image_fps), 1)),\n",
    "                                                                   np.zeros(len(image_fps))))\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "num_classes = 2\n",
    "img_size = 1024\n",
    "print(\"your device: {}\".format(device))\n",
    "\n",
    "params = {\"img_size\": img_size, \"num_classes\": num_classes, \"num_epochs\": 5, \"device\": device}\n",
    "\n",
    "images_files = np.array(image_fps)\n",
    "\n",
    "make_validation(images_files=images_files, cv=cv, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции для получения итоговых предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_image(img_path, img_size):\n",
    "    ds = pydicom.read_file(img_path)\n",
    "    image = ds.pixel_array\n",
    "    image = np.array(Image.fromarray(image).resize((img_size, img_size)))\n",
    "    if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "        image = np.stack((image,) * 3, -1)\n",
    "    image = np.rollaxis(image, 2, 0) / 255\n",
    "    return torch.Tensor(image)\n",
    "\n",
    "\n",
    "def get_test_predictions(model, test_images, device, img_size):\n",
    "    \"\"\"\n",
    "    Предсказания для теста\n",
    "    \"\"\"\n",
    "    sub = []\n",
    "    min_conf = 0\n",
    "    imgs_info = []\n",
    "    scale_factor = 1024 / img_size\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for img_path in tqdm_notebook(test_images):\n",
    "            images = [load_test_image(img_path, img_size)]\n",
    "            images = list(img.to(device) for img in images)\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            outputs = model(images)\n",
    "            outputs = [{k: v.to(device) for k, v in t.items()} for t in outputs]\n",
    "\n",
    "            boxes_pred_mini_batch = [np.array(res[\"boxes\"].to(\"cpu\")) for res in outputs]\n",
    "            scores_mini_batch = [np.array(res[\"scores\"].to(\"cpu\")) for res in outputs]\n",
    "\n",
    "            for i in range(len(images)):\n",
    "                patient_id = img_path.split(\".dcm\")[0].split(\"stage_2_test_images/\")[-1]\n",
    "                img_info = dict()\n",
    "                img_info[\"patient_id\"] = patient_id\n",
    "                img_info[\"boxes\"] = boxes_pred_mini_batch[i]\n",
    "                img_info[\"scores\"] = scores_mini_batch[i]\n",
    "                imgs_info.append(img_info)                \n",
    "    return imgs_info\n",
    "\n",
    "\n",
    "def get_sub_list(imgs_info, img_size, min_conf=0.7):\n",
    "    \"\"\"\n",
    "    Записываем предсказания в правильном формате\n",
    "    \"\"\"\n",
    "    sub = []\n",
    "    scale_factor = 1024 / img_size\n",
    "    for img_info in imgs_info:\n",
    "        patient_id = img_info[\"patient_id\"]\n",
    "        boxes_pred_mini_batch = img_info[\"boxes\"]\n",
    "        scores_mini_batch = img_info[\"scores\"]\n",
    "\n",
    "        result_str = \"{},\".format(patient_id)\n",
    "        for bbox_num in range(boxes_pred_mini_batch.shape[0]):\n",
    "            if scores_mini_batch[bbox_num] > min_conf:\n",
    "                result_str += \" {:1.2f} \".format(np.round(scores_mini_batch[bbox_num], 2))\n",
    "                x_min = int(np.round(boxes_pred_mini_batch[bbox_num, 0] * scale_factor))\n",
    "                y_min = int(np.round(boxes_pred_mini_batch[bbox_num, 1] * scale_factor))\n",
    "                width = int(np.round(boxes_pred_mini_batch[bbox_num, 2] * scale_factor)) - x_min\n",
    "                height = int(np.round(boxes_pred_mini_batch[bbox_num, 3] * scale_factor)) - y_min\n",
    "                result_str += \"{} {} {} {}\".format(x_min, y_min, width, height)\n",
    "        sub.append(result_str + \"\\n\")\n",
    "    return sub\n",
    "\n",
    "\n",
    "def write_submission(sub, filename=\"submission.csv\"):\n",
    "    with open(filename, mode=\"w\") as f:\n",
    "        header = \"patientId,PredictionString\\n\"\n",
    "        f.write(header)\n",
    "        for line in sub:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(num_classes=num_classes)\n",
    "model.load_state_dict(torch.load(\"fold_num_0_model\"))\n",
    "model.to(device)\n",
    "\n",
    "test_images = get_dicom_fps(os.path.join(data_path, \"stage_2_test_images\"))\n",
    "\n",
    "imgs_info = get_test_predictions(model, test_images, device, img_size)\n",
    "\n",
    "# min_conf -- минимальный порог уверенности для того, чтобы считать объект пневмонией\n",
    "sub_list = get_sub_list(imgs_info, img_size, min_conf=0.7)\n",
    "\n",
    "write_submission(sub_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "\n",
    "С помощью __pytorch__ сделайте следующие шаги, чтобы побить базовое решение.\n",
    "\n",
    "## Обязательная часть (50 баллов)\n",
    "* Добавить аугментацию при обучении (повороты, масштабирование, crop) — 20 баллов\n",
    "* Усреднить предсказания нескольких моделей (выбрать один из вариантов: одна модель, обученная на разных фолдах; одна модель с разными random seed; разные модели) — 10 баллов\n",
    "* Попробовать использовать MaskRCNN вместо FasterRCNN — 20 баллов\n",
    "\n",
    "## Дополнительная часть\n",
    "* Попробовать аугментацию для теста (усреднять предсказания для разных представлений одной картинки) — 10 баллов\n",
    "* Попробовать модели для сегментации (DeepLab, ...) — от 20 баллов, уточнять у преподавателя\n",
    "* Любые другие идеи, позволяющие увеличить метрику на лидерборде — баллы уточнять у преподавателя\n",
    "\n",
    "## Формат\n",
    "\n",
    "Для проверки качества моделей будут использованы сабмиты на старом соревновании kaggle https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/submit\n",
    "\n",
    "В качестве решения ДЗ принимается архив со следующим содержимым:\n",
    "* код и инструкция по запуску, позволяющий получить submission.csv (фиксируйте random seed для воспроизводимости)\n",
    "* файл submission.csv (который можно загрузить на kaggle и получить ваш score)\n",
    "* скриншот этого сабмита на kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
